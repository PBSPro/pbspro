/*
 * Copyright (C) 1994-2020 Altair Engineering, Inc.
 * For more information, contact Altair at www.altair.com.
 *
 * This file is part of both the OpenPBS software ("OpenPBS")
 * and the PBS Professional ("PBS Pro") software.
 *
 * Open Source License Information:
 *
 * OpenPBS is free software. You can redistribute it and/or modify it under
 * the terms of the GNU Affero General Public License as published by the
 * Free Software Foundation, either version 3 of the License, or (at your
 * option) any later version.
 *
 * OpenPBS is distributed in the hope that it will be useful, but WITHOUT
 * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Affero General Public
 * License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 *
 * Commercial License Information:
 *
 * PBS Pro is commercially licensed software that shares a common core with
 * the OpenPBS software.  For a copy of the commercial license terms and
 * conditions, go to: (http://www.pbspro.com/agreement.html) or contact the
 * Altair Legal Department.
 *
 * Altair's dual-license business model allows companies, individuals, and
 * organizations to create proprietary derivative works of OpenPBS and
 * distribute them - whether embedded or bundled with other software -
 * under a commercial license agreement.
 *
 * Use of Altair's trademarks, including but not limited to "PBS™",
 * "OpenPBS®", "PBS Professional®", and "PBS Pro™" and Altair's logos is
 * subject to Altair's trademark licensing policies.
 */

/**
 * contains functions related to PBS scheduler
 */
#include <pbs_config.h> /* the master config generated by configure */

#include <stdio.h>

#include "fifo.h"
#include "log.h"
#include "sched_cmds.h"
<<<<<<< HEAD
=======
#include "server_limits.h"
#include "tpp.h"

#define START_CLIENTS 2	     /* minimum number of clients */
auto okclients = std::vector<pbs_net_t>();	/* accept connections from */
char *configfile = NULL;     /* name of file containing
						 client names to be added */

extern char *msg_daemonname;
char **glob_argv;
char usage[] = "[-d home][-L logfile][-p file][-I schedname][-n][-N][-c clientsfile][-t num threads]";
struct sockaddr_in saddr;
sigset_t allsigs;


/* if we received a sigpipe, this probably means the server went away. */

/* used in segv restart */
time_t segv_start_time;
time_t segv_last_time;

#ifdef NAS /* localmod 030 */
extern int do_soft_cycle_interrupt;
extern int do_hard_cycle_interrupt;
#endif /* localmod 030 */

extern char *msg_startup1;

static pthread_mutex_t cleanup_lock;

static void close_servers();
static void reconnect_servers();
static void sched_svr_init(void);
static void connect_svrpool();
static int schedule_wrapper(sched_cmd *cmd, int opt_no_restart);

/**
 * @brief
 * 		cleanup after a segv and re-exec.  Trust as little global mem
 * 		as possible... we don't know if it could be corrupt
 *
 * @param[in]	sig	-	signal
 */
void
on_segv(int sig)
{
	int ret_lock = -1;

	/* We want any other threads to block here, we want them alive until abort() is called
	 * as it dumps core for all threads
	 */
	ret_lock = pthread_mutex_lock(&cleanup_lock);
	if (ret_lock != 0)
		pthread_exit(NULL);

	/* we crashed less then 5 minutes ago, lets not restart ourself */
	if ((segv_last_time - segv_start_time) < 300) {
		log_record(PBSEVENT_SYSTEM, PBS_EVENTCLASS_SERVER, LOG_INFO, __func__,
				"received a sigsegv within 5 minutes of start: aborting.");

		/* Not unlocking mutex on purpose, we need to hold on to it until the process is killed */
		abort();
	}

	log_record(PBSEVENT_SYSTEM, PBS_EVENTCLASS_SERVER, LOG_INFO, __func__,
			"received segv and restarting");

	if (fork() > 0) { /* the parent rexec's itself */
		sleep(10); /* allow the child to die */
		execv(glob_argv[0], glob_argv);
		exit(3);
	} else {
		abort(); /* allow to core and exit */
	}
}

/**
 * @brief
 * 		signal function for receiving a sigpipe - set flag so we know not to talk
 * 		to the server any more and leave the cycle as soon as possible
 *
 * @param[in]	sig	-	sigpipe
 */
void
sigfunc_pipe(int sig)
{
	log_record(PBSEVENT_SYSTEM, PBS_EVENTCLASS_SERVER, LOG_INFO, "sigfunc_pipe", "We've received a sigpipe: The server probably died.");
	got_sigpipe = 1;
}


/**
 * @brief
 *       Clean up after a signal.
 *
 *  @param[in]	sig	-	signal
 */
void
die(int sig)
{
	int ret_lock = -1;

	ret_lock = pthread_mutex_trylock(&cleanup_lock);
	if (ret_lock != 0)
		pthread_exit(NULL);

	if (sig > 0)
		log_eventf(PBSEVENT_SYSTEM, PBS_EVENTCLASS_SERVER, LOG_INFO, __func__, "caught signal %d", sig);
	else
		log_event(PBSEVENT_SYSTEM, PBS_EVENTCLASS_SERVER, LOG_INFO, __func__, "abnormal termination");

	close_servers();
	schedexit();

	{
		int csret;
		if ((csret = CS_close_app()) != CS_SUCCESS) {
			/*had some problem closing the security library*/

			sprintf(log_buffer, "problem closing security library (%d)", csret);
			log_err(-1, "pbs_sched", log_buffer);
		}
	}

	unload_auths();

	log_close(1);
	exit(1);
}

/**
 * @brief
 * 		add a new client to the list of clients.
 *
 * @param[in]	name	-	Client name.
 */
int
addclient(const char *name)
{
	int	i;
	struct	hostent		*host;
	struct  in_addr saddr;

	if ((host = gethostbyname(name)) == NULL) {
		sprintf(log_buffer, "host %s not found", name);
		log_err(-1, __func__, log_buffer);
		return -1;
	}

	for (i = 0; host->h_addr_list[i]; i++) {
		memcpy((char *)&saddr, host->h_addr_list[i], host->h_length);
		okclients.push_back(saddr.s_addr);
	}
	return 0;
}

/**
 * @brief
 * 		read_config - read and process the configuration file (see -c option)
 * @par
 *		Currently, the only statement is $clienthost to specify which systems
 *		can contact the scheduler.
 *
 * @param[in]	file	-	configuration file
 *
 * @return	int
 * @retval	0	: Ok
 * @retval	-1	: !nOtOk!
 */
#define CONF_LINE_LEN 120

static
int
read_config(char *file)
{
	FILE	*conf;
	int	i;
	char	line[CONF_LINE_LEN];
	char	*token;
	struct	specialconfig {
		const char	*name;
		int	(*handler)(const char *);
	} special[] = {
		{"clienthost",	addclient },
		{ NULL,		NULL }
	};


#if !defined(DEBUG) && !defined(NO_SECURITY_CHECK)
	if (chk_file_sec_user(file, 0, 0, S_IWGRP|S_IWOTH, 1, getuid()))
		return (-1);
#endif

	if ((conf = fopen(file, "r")) == NULL) {
		log_err(errno, __func__, "cannot open config file");
		return (-1);
	}
	while (fgets(line, CONF_LINE_LEN, conf)) {

		if ((line[0] == '#') || (line[0] == '\n'))
			continue;		/* ignore comment & null line */
		else if (line[0] == '$') {	/* special */

			if ((token = strtok(line, " \t")) == NULL)
				token = const_cast<char *>("");
			for (i=0; special[i].name; i++) {
				if (strcmp(token+1, special[i].name) == 0)
					break;
			}
			if (special[i].name == NULL) {
				sprintf(log_buffer, "config name %s not known",
					token);
				log_record(PBSEVENT_ERROR,
					PBS_EVENTCLASS_SERVER, LOG_INFO,
					msg_daemonname, log_buffer);
				continue;
			}
			token = strtok(NULL, " \t");
			if (*(token+strlen(token)-1) == '\n')
				*(token+strlen(token)-1) = '\0';
			if (special[i].handler(token)) {
				fclose(conf);
				return (-1);
			}

		} else {
			log_record(PBSEVENT_ERROR, PBS_EVENTCLASS_SERVER,
				LOG_INFO, msg_daemonname,
				"invalid line in config file");
			fclose(conf);
			return (-1);
		}
	}
	fclose(conf);
	return (0);
}
/**
 * @brief
 * 		restart on signal
 *
 * @param[in]	sig	-	signal
 */
void
restart(int sig)
{
	const sched_cmd cmd = {SCH_CONFIGURE, NULL};

	if (sig) {
		log_close(1);
		log_open(logfile, path_log);
		sprintf(log_buffer, "restart on signal %d", sig);
	} else {
		sprintf(log_buffer, "restart command");
	}
	log_record(PBSEVENT_SYSTEM, PBS_EVENTCLASS_SERVER, LOG_INFO, __func__, log_buffer);
	if (configfile) {
		if (read_config(configfile) != 0)
			die(0);
	}
	schedule(clust_primary_sock, &cmd);
}

#ifdef NAS /* localmod 030 */
/**
 * @brief
 * 		make soft cycle interrupt active
 *
 * @param[in]	sig	-	signal
 */
void
soft_cycle_interrupt(int sig)
{
	do_soft_cycle_interrupt = 1;
}
/**
 * @brief
 * 		make hard cycle interrupt active
 *
 * @param[in]	sig	-	signal
 */
void
hard_cycle_interrupt(int sig)
{
	do_hard_cycle_interrupt = 1;
}
#endif /* localmod 030 */
/**
 * @brief
 * 		log the bad connection message
 *
 * @param[in]	msg	-	The message to be logged.
 */
void
badconn(const char *msg)
{
	struct in_addr addr;
	char buf[5 * sizeof(addr) + 100];
	struct hostent *phe;

	addr = saddr.sin_addr;
	phe = gethostbyaddr((void *) &addr, sizeof(addr), AF_INET);
	if (phe == NULL) {
		char hold[6];
		size_t i;
		union {
			struct in_addr aa;
			u_char bb[sizeof(addr)];
		} uu;

		uu.aa = addr;
		sprintf(buf, "%u", (unsigned int) uu.bb[0]);
		for (i = 1; i < sizeof(addr); i++) {
			sprintf(hold, ".%u", (unsigned int) uu.bb[i]);
			strcat(buf, hold);
		}
	} else
		pbs_strncpy(buf, phe->h_name, sizeof(buf));

	log_errf(-1, __func__, "%s on port %u %s", buf, (unsigned int) ntohs(saddr.sin_port), msg);
	return;
}

/**
 * @brief
 * 		lock_out - lock out other daemons from this directory.
 *
 * @param[in]	fds	-	file descriptor
 * @param[in]	op	-	F_WRLCK  or  F_UNLCK
 *
 * @return	1
 */

static void
lock_out(int fds, int op)
{
	struct flock flock;

	(void)lseek(fds, (off_t)0, SEEK_SET);
	flock.l_type   = op;
	flock.l_whence = SEEK_SET;
	flock.l_start  = 0;
	flock.l_len    = 0;	/* whole file */
	if (fcntl(fds, F_SETLK, &flock) < 0) {
		log_err(errno, msg_daemonname, "another scheduler running");
		fprintf(stderr, "pbs_sched: another scheduler running\n");
		exit(1);
	}
}

/**
 * @brief
 * 		are_we_primary - are we on the primary Server host
 *		If either the only configured Server or the Primary in a failover
 *		configuration - return true
 *
 * @return	int
 * @retval	0	: we are the secondary
 * @retval	-1	: cannot be neither
 * @retval	1	: we are the listed primary
 */
static int
are_we_primary()
{
	char server_host[PBS_MAXHOSTNAME+1];
	char hn1[PBS_MAXHOSTNAME+1];

	if (pbs_conf.pbs_leaf_name) {
		char *endp;
		snprintf(server_host, sizeof(server_host), "%s", pbs_conf.pbs_leaf_name);
		endp = strchr(server_host, ','); /* find the first name */
		if (endp)
			*endp = '\0';
		endp = strchr(server_host, ':'); /* cut out the port */
		if (endp)
			*endp = '\0';
	} else if ((gethostname(server_host, (sizeof(server_host) - 1)) == -1) ||
		(get_fullhostname(server_host, server_host, (sizeof(server_host) - 1)) == -1)) {
		log_err(-1, __func__, "Unable to get my host name");
		return -1;
	}

	/* both secondary and primary should be set or neither set */
	if ((pbs_conf.pbs_secondary == NULL) && (pbs_conf.pbs_primary == NULL))
		return 1;
	if ((pbs_conf.pbs_secondary == NULL) || (pbs_conf.pbs_primary == NULL))
		return -1;

	if (get_fullhostname(pbs_conf.pbs_primary, hn1, (sizeof(hn1) - 1))==-1) {
		log_err(-1, __func__, "Unable to get full host name of primary");
		return -1;
	}

	if (strcmp(hn1, server_host) == 0)
		return 1;	/* we are the listed primary */

	if (get_fullhostname(pbs_conf.pbs_secondary, hn1, (sizeof(hn1) - 1))==-1) {
		log_err(-1, __func__, "Unable to get full host name of secondary");
		return -1;
	}
	if (strcmp(hn1, server_host) == 0)
		return 0;	/* we are the secondary */

	return -1;		/* cannot be neither */
}

/**
 * @brief close connections to all servers
 *
 * @return void
 */
static void
close_servers(void)
{
	int i;

	pbs_disconnect(clust_primary_sock);
	pbs_disconnect(clust_secondary_sock);

	if (poll_context != NULL) {
		tpp_em_destroy(poll_context);
		poll_context = NULL;
	}

	/* free qrun_list */
	for (i = 0; i < qrun_list_size; i++) {
		if (qrun_list[i].jid != NULL)
			free(qrun_list[i].jid);
	}
	free(qrun_list);

	sched_svr_init();

	clust_primary_sock = -1;
	clust_secondary_sock = -1;
}

/**
 * @brief connect to all the servers configured. Also add secondary connections
 *              of individual servers secondary sd's to the poll list
 *
 *
 * @return void
 */
static void
connect_svrpool()
{
	int i;
	svr_conn_t *svr_conns_primary = NULL;
	svr_conn_t *svr_conns_secondary = NULL;
	int num_conf_svrs = get_num_servers();


	while (1) {
		/* pbs_connect() will return a connection handle for all servers
		 * we have to close all servers before pbs_conenct is reattempted
		 */
		if (clust_primary_sock < 0) {
			clust_primary_sock = pbs_connect(NULL);
			if (clust_primary_sock < 0) {
				/* wait for 2s for not to burn too much CPU, and then retry connection */
				sleep(2);
				close_servers();
				continue;
			}
		}
		clust_secondary_sock = pbs_connect(NULL);
		if (clust_secondary_sock < 0) {
			/* wait for 2s for not to burn too much CPU, and then retry connection */
			sleep(2);
			close_servers();
			continue;
		}

		svr_conns_primary =  static_cast<svr_conn_t *>(get_conn_svr_instances(clust_primary_sock));
		svr_conns_secondary =  static_cast<svr_conn_t *>(get_conn_svr_instances(clust_secondary_sock));

		if (svr_conns_primary == NULL || svr_conns_secondary == NULL) {
			/* wait for 2s for not to burn too much CPU, and then retry connection */
			sleep(2);
			close_servers();
			continue;	
		}

		for (i = 0; i < num_conf_svrs; i++) {
			if (svr_conns_primary[i].state == SVR_CONN_STATE_DOWN || svr_conns_primary[i].state == SVR_CONN_STATE_DOWN) {	
				if (svr_conns_primary[i].state == SVR_CONN_STATE_DOWN)
					clust_primary_sock = -1;
				if (svr_conns_secondary[i].state == SVR_CONN_STATE_DOWN)
					clust_secondary_sock = -1;
				break;
			}
		}

		if (i != num_conf_svrs) {
			/* If we reached here means one of the servers is down or not connected
			 * we should go to the top of the loop again and call pbs_connect
			 * Also wait for 2s for not to burn too much CPU
			 */
			sleep(2);
			close_servers();
			continue;
		}

		if (pbs_register_sched(sc_name, clust_primary_sock, clust_secondary_sock) == 0) {
			log_errf(pbs_errno, __func__, "Couldn't register the scheduler %s with the configured servers", sc_name);
			/* wait for 2s for not to burn too much CPU, and then retry connection */
			sleep(2);
			close_servers();			
			continue;
		}

		/* Reached here means everything is success, so we will break out of the loop */
		break;
		
	}


	log_eventf(PBSEVENT_ADMIN | PBSEVENT_FORCE, PBS_EVENTCLASS_SCHED, LOG_INFO, msg_daemonname, "Connected to all the configured servers");
	for (i = 0; i < get_num_servers(); i++) {
		if (tpp_em_add_fd(poll_context, svr_conns_secondary[i].sd, EM_IN | EM_HUP | EM_ERR) < 0) {
			log_errf(errno, __func__, "Couldn't add secondary connection to poll list for server %s", svr_conns_secondary[i].name);
			die(-1);
		}
	}
}

/**
 * @brief Initialises event poll context for all the servers and also sched commands queue
 *
 * @return void
 */
static void
sched_svr_init(void)
{
	if (poll_context == NULL) {
		poll_context = tpp_em_init(get_num_servers());
		if (poll_context == NULL) {
			log_err(errno, __func__, "Failed to init cmd connections context");
			die(-1);
		}
	}

	qrun_list = static_cast<sched_cmd *>(malloc((get_num_servers() + 1) * sizeof(sched_cmd)));
	if (qrun_list == NULL) {
		log_err(errno, __func__, MEM_ERR_MSG);
		die(0);
	}

}

/**
 * @brief reconnect to all the servers configured
 *
 * @return void
 */
static void
reconnect_servers()
{

	close_servers();
	connect_svrpool();
}

/**
 * @brief read incoming command from given secondary connection
 *        and add it into sched_cmds array
 *
 * @param[in]  sock   - secondary connection to server
 *
 * @return int
 * @retval -2 - failure due to memory operation failed
 * @retval -1 - failure while reading command
 * @return  0 - no cmd, server might have closed connection
 * @return  1 - success, read atleast one command
 */
static int
read_sched_cmd(int sock)
{
	int rc = -1;
	sched_cmd cmd;

	rc = get_sched_cmd(sock, &cmd);
	if (rc != 1)
		return rc;
	else {
		sched_cmd cmd_prio;
		/*
		 * There is possibility that server has sent
		 * priority command after first non-priority command,
		 * while we were in schedule()
		 *
		 * so try read it in non-blocking mode, but don't
		 * return any failure if fails to read, as we have
		 * successfully enqueued first command
		 *
		 * and if we get priority command then just ignore it
		 * since we are not yet in middle of schedule cycle
		 */
		int rc_prio = get_sched_cmd_noblk(sock, &cmd_prio);
		if (rc_prio == -2)
			return 0;
	}

	if (cmd.cmd != SCH_SCHEDULE_RESTART_CYCLE)  {
		if (cmd.cmd == SCH_SCHEDULE_AJOB)
			qrun_list[qrun_list_size++] = cmd;
		else {
			if (cmd.cmd >= SCH_SCHEDULE_NULL && cmd.cmd < SCH_CMD_HIGH)
				sched_cmds[cmd.cmd] = 1;
		}

	}

	return rc;
}

/**
 * @brief wait for commands from servers
 *
 * @return void
 */
static void
wait_for_cmds()
{
	int nsocks;
	int i;
	em_event_t *events;
	int err;
	int hascmd = 0;
	sigset_t emptyset;

	qrun_list_size = 0;
>>>>>>> Making Scheduler's job related APIs work on the right server as jobs are sharded in Multi-Server

extern int sched_main(int argc, char *argv[], int (*schedule_func)(int, const sched_cmd *));

int
main(int argc, char *argv[])
{
	if (set_msgdaemonname(const_cast<char *>("pbs_sched"))) {
		fprintf(stderr, "Out of memory\n");
		return (1);
	}

	return sched_main(argc, argv, schedule);
}
